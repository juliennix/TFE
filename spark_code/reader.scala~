/////////////////////////////////////////////////////////////////
// Author : Nix Julien                                         //        
// For the University of LiÃ¨ge                                 //     
// Date : 06/02/2015                                           //
// This manages files                                          //
///////////////////////////////////////////////////////////////// 

package reader

import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf

object Reader 
{     
    def intList(l : List[String]) = l.map(x=>Integer.parseInt(x))
    
    def FileMapReader(absPath:String, labelDelimiter:String, delimiter:String): org.apache.spark.rdd.RDD[(Float, Array[Float])] =
    {  
        //val conf = new SparkConf().setAppName("Simple Application")
        //val sc = new SparkContext(conf)
        println("Now reading... " + absPath)
        val data = sc.textFile(absPath)
        val dataRDD = data.map 
        { 
            line =>
            val parts = line.split("""\""" + labelDelimiter)
            (parts(0).toFloat, parts(1).split("""\""" + delimiter).map(_.toFloat))
        }
        return dataRDD
    }   
}
